{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEE 197z Project 1 - Zero Shot Object Detection\n",
    "use SAM to perform zero-shot object detection using COCO 2017 val split. \n",
    "\n",
    "*Author: Sean Red Mendoza | 2020-01751 | scmendoza5@up.edu.ph*\n",
    "\n",
    "## Tools/ References\n",
    "- [SegmentAnything](https://github.com/facebookresearch/segment-anything)\n",
    "- [OpenClip](https://github.com/mlfoundations/open_clip)\n",
    "- [Coco 2017 Validation Dataset](https://cocodataset.org/#home)\n",
    "- [roatienza/mlops](https://github.com/roatienza/mlops)\n",
    "- [roatienza/Deep-Learning-Experiments](https://github.com/roatienza/Deep-Learning-Experiments)\n",
    "- [Google Cloud G2 GPU VM (Nvidia L4)](https://cloud.google.com/blog/products/compute/introducing-g2-vms-with-nvidia-l4-gpus)\n",
    "\n",
    "## Goals\n",
    "\n",
    "## Approach\n",
    "\n",
    "## Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import os\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import json\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "print(\"[setup]: determining CUDA support...\")\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean output directory\n",
    "if not os.path.exists(\"../output\"):\n",
    "    os.mkdir(f\"../output\")\n",
    "shutil.rmtree(\"../output/\")\n",
    "os.mkdir(f\"../output/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "This program supports manual entry of input image links or random sampling from the CoCo 2017 Validation Dataset\n",
    "*Please select your desired input method below:*\n",
    "\n",
    "- [1] Input Images\n",
    "- [2] CoCo Images\n",
    "\n",
    "After selecting the input image source, you will be asked to input the following:\n",
    "- [a] List of image URL strings, or\n",
    "- [b] number of random images sourced from CoCo 2017*\n",
    "\n",
    "**a hard limit of 10 images is set to prevent overloading of the system*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_input():\n",
    "    while True:\n",
    "        user_input = input(\"Enter 1 or 2: \")\n",
    "        if user_input in ['1', '2']:\n",
    "            return int(user_input)\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 1 or 2.\")\n",
    "            \n",
    "def get_valid_number(n):\n",
    "    while True:\n",
    "        user_input = input(\"Enter an integer from 1 to {}: \".format(n))\n",
    "        if user_input.isdigit():\n",
    "            number = int(user_input)\n",
    "            if 1 <= number <= n:\n",
    "                return number\n",
    "        print(\"Invalid input. Please enter an integer from 1 to {}.\".format(n))\n",
    "\n",
    "input_type = get_valid_input()\n",
    "\n",
    "if input_type == 1:\n",
    "    print(\"You have selected MANUAL_INPUT, please enter the image URLs in the following block\")\n",
    "elif input_type==2:\n",
    "    input_image_count = get_valid_number(10)\n",
    "    print(f\"You have selected RANDOM_INPUT of {input_image_count} images from the CoCo 2017 dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[0]: loading coco annotations and captions...\")\n",
    "dataDir = '../coco'\n",
    "dataType = 'val2017'\n",
    "annFile = '{}/annotations/instances_{}.json'.format(dataDir, dataType)\n",
    "# initialize COCO api for instance annotations + COCO ground truth api\n",
    "cocoGt = COCO(annFile)\n",
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir, dataType)\n",
    "coco_caps = COCO(annFile)\n",
    "catIDs = cocoGt.getCatIds()\n",
    "\n",
    "# get all captions\n",
    "annIds = coco_caps.getAnnIds(imgIds=[], catIds=[])\n",
    "anns = coco_caps.loadAnns(annIds)\n",
    "coco_labels_words = []\n",
    "for ann in anns:\n",
    "    words = ann['caption'].split()\n",
    "    for word in words:\n",
    "        clean_word = re.sub(r'[^a-zA-Z0-9\\s]', '', word.lower())\n",
    "        coco_labels_words.append(clean_word)\n",
    "\n",
    "coco_labels_words_values = list(set(coco_labels_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_IDs = []\n",
    "input_image_catIDs = []\n",
    "input_image_URLs = []\n",
    "input_image_areas = []\n",
    "input_image_labels = []\n",
    "\n",
    "## RANDOM INPUT\n",
    "def get_random_coco_image(n):\n",
    "    for i in range(n):\n",
    "        # get random coco image\n",
    "        catID = catIDs[np.random.randint(0, len(catIDs))]\n",
    "        catImages = cocoGt.getImgIds(catIds=[catID])\n",
    "        imgID = catImages[np.random.randint(0, len(catImages))]\n",
    "        # build image meta data\n",
    "        img = cocoGt.loadImgs(imgID)[0]\n",
    "        imgArea = img['height']*img['width']\n",
    "        imgURL = img['coco_url']\n",
    "        # fetch ground truth labels from coco\n",
    "        annIds = coco_caps.getAnnIds(imgIds=imgID)\n",
    "        anns = coco_caps.loadAnns(annIds)\n",
    "        ground_truth_labels = list(map(lambda x: x['caption'], anns))\n",
    "        input_image_IDs.append(imgID)\n",
    "        input_image_catIDs.append(catID)\n",
    "        input_image_URLs.append(imgURL)\n",
    "        input_image_areas.append(imgArea)\n",
    "        input_image_labels.append(ground_truth_labels)\n",
    "\n",
    "random_images = get_random_coco_image(input_image_count)    \n",
    "\n",
    "## MODIFY FOR MANUAL INPUT\n",
    "if input_type == 1:\n",
    "    input_images_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[1]: loading sam model\")\n",
    "sam_checkpoint = os.path.join(\"../checkpoints\", \"sam_vit_h_4b8939.pth\")\n",
    "model_type = \"vit_h\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,\n",
    "    points_per_batch=64,\n",
    "    pred_iou_thresh=0.8,\n",
    "    box_nms_thresh=0.3,\n",
    "    stability_score_thresh=0.9,\n",
    "    min_mask_region_area=1000,  # Requires open-cv to run post-processing\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[2]: creating open clip model...\")\n",
    "modelType = 'ViT-B-32-quickgelu'\n",
    "modelDataset = \"laion400m_e31\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    modelType, pretrained=modelDataset)\n",
    "tokenizer = open_clip.get_tokenizer(modelType)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"[2]: loading coco categories as labels...\")\n",
    "text = tokenizer(coco_labels_words_values)\n",
    "text = text.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
